{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from models.hdisc_msda import Disc_MSDANet, weighted_mse\n",
    "from models.MDAN import MDANet_general\n",
    "from utils.load_amazon import load_amazon\n",
    "from utils.utils_hdisc import batch_loader, split_source_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading\n",
    "X_amazon, y_amazon, domain_list = load_amazon(filepath='./data/amazon_tf-idf.npz', domains=None)\n",
    "#Standardize labels\n",
    "mu_y = np.mean(np.concatenate(y_amazon))\n",
    "std_y = np.std(np.concatenate(y_amazon))\n",
    "print(std_y)\n",
    "y_amazon = [(y-mu_y)/std_y for y in y_amazon]\n",
    "#y_amazon = [y-3 for y in y_amazon]\n",
    "#Number of domains\n",
    "n_domains = len(X_amazon)\n",
    "\n",
    "#Seed for reproducible results\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def get_feature_extractor(input_dim=X_amazon[0].shape[1]):\n",
    "    return nn.ModuleList([\n",
    "            nn.Linear(1000, 500, bias=False), nn.ELU(), nn.Dropout(p=0.1),\n",
    "            nn.Linear(500, 20, bias=False), nn.ELU(), nn.Dropout(p=0.1)])\n",
    "\n",
    "def get_predictor(output_dim=1):\n",
    "    return  nn.ModuleList([\n",
    "            #nn.Linear(100,10, bias=False), nn.ELU(), nn.Dropout(p=0.1),\n",
    "            nn.Linear(20, output_dim, bias=False)])\n",
    "\n",
    "def get_discriminator(output_dim=1):\n",
    "    return nn.ModuleList([\n",
    "            #nn.Linear(100, 10, bias=False), nn.ELU(), nn.Dropout(p=0.1),\n",
    "            nn.Linear(20, output_dim, bias=False)])\n",
    "    \n",
    "    \n",
    "def save_result(result, filepath, domain_list):\n",
    "    median = {}\n",
    "    for k in domain_list:\n",
    "        median[k] = []\n",
    "    for r in range(len(result)):\n",
    "        for k in domain_list:\n",
    "            median[k].append(result[r][k])\n",
    "    df = pd.DataFrame(median)\n",
    "    df.to_csv(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.hdisc_msda \n",
    "importlib.reload(models.hdisc_msda)\n",
    "from models.hdisc_msda import Disc_MSDANet\n",
    "\n",
    "#Number of experiments to launch\n",
    "nb_experiments = 5\n",
    "results_mse, results_mae = [], []\n",
    "\n",
    "params= {'input_dim': X_amazon[0].shape[1], 'output_dim': 1, 'n_sources': n_domains-1, 'loss': torch.nn.MSELoss(),\n",
    "         'weighted_loss': weighted_mse, 'min_pred': -np.inf, 'max_pred': np.inf}\n",
    "\n",
    "#Number of epochs\n",
    "epochs_pretrain, epochs_adapt = 0, 100\n",
    "epochs_h_disc, epochs_feat, epochs_alpha, epochs_pred = 1, 1, 1, 1\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "for exp in range(nb_experiments):\n",
    "    print('\\n ----------------------------- %i / %i -----------------------------'%(exp+1, nb_experiments))\n",
    "    mse_list, mae_list =  {}, {}\n",
    "    alphas = {}\n",
    "    for i in range(len(domain_list)):\n",
    "        domain = domain_list[i]\n",
    "        #Split source and target\n",
    "        X_s, X_t, y_s, y_t = split_source_target(X_amazon, y_amazon, i, device, merge=False)\n",
    "        #Initialize model\n",
    "        params['feature_extractor'] = get_feature_extractor()\n",
    "        params['h_pred'] = get_predictor(output_dim=1)\n",
    "        params['h_disc'] = get_discriminator(output_dim=1)\n",
    "        model = Disc_MSDANet(params).to(device)\n",
    "        opt_feat = torch.optim.Adam([{'params': model.feature_extractor.parameters()}],lr=lr)\n",
    "        opt_pred = torch.optim.Adam([{'params': model.h_pred.parameters()}],lr=lr)\n",
    "        opt_disc = torch.optim.Adam([{'params': model.h_disc.parameters()}],lr=lr)\n",
    "        opt_alpha = torch.optim.Adam([{'params': model.alpha}],lr=lr)\n",
    "        model.optimizers(opt_feat, opt_pred, opt_disc, opt_alpha)\n",
    "        print('----', domain, '----')\n",
    "        #Pre-training\n",
    "        print('------------Pre-training------------')\n",
    "        for epoch in range(epochs_pretrain):\n",
    "            loader = batch_loader(X_s, y_s ,batch_size = batch_size)\n",
    "            for x_bs, y_bs in loader:\n",
    "                loss_pred = model.train_prediction(x_bs, X_t, y_bs, clip=1, pred_only=False)\n",
    "            if (epoch+1)%1==0:\n",
    "                source_loss, disc = model.compute_loss(X_s, X_t, y_s)\n",
    "                reg_loss = model.loss(y_t, model.predict(X_t))\n",
    "                print('Epoch: %i/%i ; Train loss: %.3f ; Disc: %.3f ; Test loss: %.3f'%(epoch+1, epochs_pretrain, source_loss.item(), disc.item(), reg_loss.item()))\n",
    "\n",
    "        #Alternated training\n",
    "        print('------------Alternated training------------')\n",
    "        for epoch in range(epochs_adapt):\n",
    "            model.train()\n",
    "            loader = batch_loader(X_s, y_s ,batch_size = batch_size)\n",
    "            for x_bs, y_bs in loader:\n",
    "                ridx = np.random.choice(X_t.shape[0], batch_size)\n",
    "                x_bt = X_t[ridx,:]\n",
    "                #Train h to minimize source loss\n",
    "                for e in range(epochs_pred):\n",
    "                    model.train_prediction(x_bs, x_bt, y_bs, pred_only=False)\n",
    "\n",
    "                #Train h' to maximize discrepancy\n",
    "                for e in range(epochs_h_disc):\n",
    "                    model.train_h_discrepancy(x_bs, x_bt, y_bs)\n",
    "                \n",
    "                #Train phi to minimize discrepancy\n",
    "                for e in range(epochs_feat):\n",
    "                    model.train_feat_discrepancy(x_bs, x_bt, y_bs, mu=0)\n",
    "                    \n",
    "                #Train alpha to minimize discrepancy\n",
    "                for e in range(epochs_alpha):\n",
    "                    model.train_alpha_discrepancy(x_bs, x_bt, y_bs, clip=1, lam_alpha=0.1)\n",
    "\n",
    "            #Logs\n",
    "            if (epoch+1)%100==0:\n",
    "                model.eval()\n",
    "                source_loss, disc = model.compute_loss(X_s, X_t, y_s)\n",
    "                reg_loss = model.loss(y_t, model.predict(X_t))\n",
    "                print('Epoch: %i/%i (h_pred); Train loss: %.3f ; Disc: %.3f ; Test loss: %.3f'%(epoch+1, epochs_adapt, source_loss.item(), disc.item(), reg_loss.item()))\n",
    "        mse_list[domain] = model.loss(y_t, model.predict(X_t)).item()\n",
    "        mae_list[domain] = torch.sum(torch.abs(y_t.squeeze_()- model.predict(X_t).squeeze_())).item()/y_t.shape[0]\n",
    "        print(mae_list[domain])\n",
    "    results_mse.append(mse_list)\n",
    "    results_mae.append(mae_list)\n",
    "    save_result(results_mse, './results/ADisc_MSDA_mse.csv', domain_list)\n",
    "    save_result(results_mae, './results/ADisc_MSDA_mae.csv', domain_list)\n",
    "save_result(results_mse, './results/ADisc_MSDA_mse.csv', domain_list)\n",
    "save_result(results_mae, './results/ADisc_MSDA_mae.csv', domain_list)\n",
    "for key, val in alphas.items():\n",
    "    w.create_dataset(name=k, data=val)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dds]",
   "language": "python",
   "name": "conda-env-dds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
